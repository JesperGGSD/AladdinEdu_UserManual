---
title: "UserManual_v1.3.0"
date: June 19, 2025
output: pdf_document
plugin: 
  name: "Aladdin"
  version: "2.3.1"
---
# AladdinEduä½¿ç”¨æ‰‹å†Œ

# ç®€ä»‹

> ä¸¥è‚ƒå£°æ˜ï¼šä¸¥ç¦æŒ–çŸ¿ï¼Œä¸€ç»å‘ç°ä¸€å¾‹æ¸…ç©ºæ‰€æœ‰ç®—åŠ›å¹¶æ°¸ä¹…å°å·ï¼

ğŸ”¹æ¬¢è¿å…³æ³¨å…¬ä¼—å·â€œä¹ç« äº‘æAladdinEduâ€ï¼Œè·å–æ›´å¤šæ´»åŠ¨ä¸ç¦åˆ©ï¼

ğŸ”¹æ•™å­¦è§†é¢‘ï¼š[AladdinEduå¹³å°ä½¿ç”¨æ•™ç¨‹ï¼ˆVSCodeç‰ˆï¼‰](https://www.bilibili.com/video/BV1bKLjz7EQk/?share_source=copy_web&vd_source=785ba0f4a2bb0a864e047ca2c9d18fed
) 

ğŸ”¹[AladdinEduï¼ŒåŒå­¦ä»¬ç”¨å¾—èµ·çš„Hå¡ç®—åŠ›å¹³å°](https://www.aladdinedu.com/)ã€‚

ğŸ”¹å¿…çœ‹æ–‡æ¡£ï¼š

  â€ƒâ€ƒ1. [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)

  â€ƒâ€ƒ2. [æ•°æ®](#æ•°æ®)
  
  â€ƒâ€ƒ3. [å……å€¼ä¸è®¡è´¹](#å……å€¼ä¸è®¡è´¹)

ä½¿ç”¨æµç¨‹å›¾ï¼š

   ![pic1](./pic/pic1.png)

æ¶æ„å›¾ï¼š

   ![frame](./pic/frame.png)

# å­¦æœ¯èµ„æºåŠ é€Ÿ

## å…¬å¼€èµ„æº

```bash
# GitHubåŠ é€Ÿ
git config --global url."https://gh-proxy.com/github.com/".insteadOf "https://github.com/"
```

## ä¸‹è½½å¹³å°å·²ç¼“å­˜æ¨¡å‹
å¹³å°ä¸­æˆ‘ä»¬ç¼“å­˜äº†å¾ˆå¤šå¼€æºæ¨¡å‹ï¼Œå¯ä»¥åŠ é€Ÿä¸‹è½½ã€‚

1. è®¾ç½®HF_ENDPOINTç¯å¢ƒå˜é‡ï¼š
```bash
export HF_ENDPOINT=http://hfmirror.mas.zetyun.cn:8082
```
2. æŸ¥çœ‹æ¨¡å‹ç¼“å­˜åˆ—è¡¨ï¼š

```bash
# å±•ç¤ºæ‰€æœ‰å·²ç¼“å­˜æ¨¡å‹åç§°
 curl -s http://hfmirror.mas.zetyun.cn:8082/repos | grep -oP '(?<=<div class="header">)[^<]+' | sort | sort
```

   <details>
      <summary>ç‚¹å‡»å±•å¼€ / æ”¶èµ·æ¨¡å‹åˆ—è¡¨</summary>

      ACE-Step/ACE-Step-v1-chinese-rap-LoRA
      AI-MO/NuminaMath-1.5
      AI-MO/NuminaMath-TIR
      AIDC-AI/Ovis1.6-Gemma2-9B
      AgentGym/AgentEval
      AgentGym/AgentEvol-7B
      AlayaNeW/QA_from_CoVLA_zh
      AlphaGaO/DeepSeek-V3-0324-Fused-8E-39B-Unhealed-Preview
      BAAI/OpenSeek-Pretrain-100B
      BAAI/ShareRobot
      BAAI/bge-m3
      BAAI/bge-reranker-base
      Bofeee5675/TongUI-143K
      ByteDance/Dolphin
      CEIA-UFG/Gemma-3-Gaia-PT-BR-4b-it
      Comfy-Org/ACE-Step_ComfyUI_repackaged
      Comfy-Org/HunyuanVideo_repackaged
      Comfy-Org/Wan_2.1_ComfyUI_repackaged
      Comfy-Org/flux1-schnell
      Comfy-Org/sigclip_vision_384
      DataCanvas/Alaya-7B-Base
      Efficient-Large-Model/NVILA-Lite-15B
      FacehugmanIII/4x_foolhardy_Remacri
      FunAudioLLM/SenseVoiceSmall
      GraydientPlatformAPI/flux-clip
      HuggingFaceTB/SmolVLM-256M-Instruct
      Jize1/GTA
      Kijai/HunyuanVideo_comfy
      Kijai/WanVideo_comfy
      Kijai/llava-llama-3-8b-text-encoder-tokenizer
      Laxhar/noobai-XL-1.1
      LeonJoe13/Sonic
      LiheYoung/depth-anything-large-hf
      OpenGVLab/InternVL2_5-26B
      OpenGVLab/InternVL2_5-38B
      OpenGVLab/InternVL2_5-4B
      OpenGVLab/InternVL2_5-78B
      OpenGVLab/InternVL2_5-8B
      OpenGVLab/InternVL3-14B-AWQ
      PRIME-RL/Eurus-2-RL-Data
      Qwen/QVQ-72B-Preview
      Qwen/QwQ-32B
      Qwen/QwQ-32B-AWQ
      Qwen/QwQ-32B-Preview
      Qwen/Qwen-7B
      Qwen/Qwen1.5-0.5B-Chat-AWQ
      Qwen/Qwen1.5-0.5B-Chat-GPTQ-Int4
      Qwen/Qwen2-0.5B-Instruct-AWQ
      Qwen/Qwen2-0.5B-Instruct-GGUF
      Qwen/Qwen2-0.5B-Instruct-MLX
      Qwen/Qwen2-7B
      Qwen/Qwen2-7B-Instruct
      Qwen/Qwen2-VL-2B-Instruct
      Qwen/Qwen2-VL-7B-Instruct
      Qwen/Qwen2.5-0.5B
      Qwen/Qwen2.5-0.5B-Instruct
      Qwen/Qwen2.5-1.5B
      Qwen/Qwen2.5-1.5B-Instruct
      Qwen/Qwen2.5-14B-Instruct
      Qwen/Qwen2.5-32B
      Qwen/Qwen2.5-32B-Instruct
      Qwen/Qwen2.5-72B
      Qwen/Qwen2.5-72B-Instruct
      Qwen/Qwen2.5-7B
      Qwen/Qwen2.5-7B-Instruct
      Qwen/Qwen2.5-Coder-0.5B-Instruct-AWQ
      Qwen/Qwen2.5-Math-7B
      Qwen/Qwen2.5-Omni-7B
      Qwen/Qwen2.5-VL-32B-Instruct
      Qwen/Qwen2.5-VL-32B-Instruct-AWQ
      Qwen/Qwen2.5-VL-3B-Instruct
      Qwen/Qwen2.5-VL-72B-Instruct
      Qwen/Qwen2.5-VL-7B-Instruct
      Qwen/Qwen3-0.6B
      Qwen/Qwen3-0.6B-Base
      Qwen/Qwen3-0.6B-FP8
      Qwen/Qwen3-1.7B
      Qwen/Qwen3-1.7B-Base
      Qwen/Qwen3-1.7B-FP8
      Qwen/Qwen3-14B
      Qwen/Qwen3-14B-Base
      Qwen/Qwen3-14B-FP8
      Qwen/Qwen3-235B-A22B
      Qwen/Qwen3-235B-A22B-FP8
      Qwen/Qwen3-30B-A3B
      Qwen/Qwen3-30B-A3B-Base
      Qwen/Qwen3-30B-A3B-FP8
      Qwen/Qwen3-32B
      Qwen/Qwen3-32B-FP8
      Qwen/Qwen3-4B
      Qwen/Qwen3-4B-Base
      Qwen/Qwen3-4B-FP8
      Qwen/Qwen3-8B
      Qwen/Qwen3-8B-Base
      Qwen/Qwen3-8B-FP8
      RUC-AIBOX/STILL-2
      RUC-AIBOX/STILL-3-TOOL-32B
      RUC-AIBOX/ds_qwen_1.5B-iter1_steps60-iter2_steps60-iter3_steps60-iter4_steps60
      RUC-AIBOX/long_form_thought_data_5k
      RedHatAI/Qwen2.5-VL-72B-Instruct-quantized.w8a8
      SGLang/DeepSeek-V3-NextN
      SamuelYang/bookcorpus
      Shakker-Labs/FLUX.1-dev-ControlNet-Union-Pro-2.0
      SynthLabsAI/Big-Math-RL-Verified
      THUDM/chatglm-6b
      THUDM/glm-4v-9b
      Virtuos-rnd/flux_upscale_model
      Vvilams/t5xxl_fp16
      Wan-AI/Wan2.1-I2V-14B-720P
      Wan-AI/Wan2.1-T2V-1.3B
      Wan-AI/Wan2.1-T2V-14B
      Wan-AI/Wan2.1-VACE-1.3B
      Wan-AI/Wan2.1-VACE-14B
      XLabs-AI/flux-furry-lora
      XLabs-AI/flux-lora-collection
      YkiWu/hoi4d_release
      agentica-org/DeepCoder-14B-Preview
      agentica-org/DeepScaleR-Preview-Dataset
      aharley/pointodyssey
      baichuan-inc/Baichuan-7B
      bert-base-uncased/paths-info
      black-forest-labs/FLUX.1-Canny-dev
      black-forest-labs/FLUX.1-Depth-dev-lora
      black-forest-labs/FLUX.1-Fill-dev
      black-forest-labs/FLUX.1-Redux-dev
      black-forest-labs/FLUX.1-dev
      black-forest-labs/FLUX.1-schnell
      bookcorpus/bookcorpus
      cagliostrolab/animagine-xl-3.1
      calcuis/wan-gguf
      camenduru/SMPLer-X
      city96/Wan2.1-I2V-14B-480P-gguf
      city96/Wan2.1-I2V-14B-720P-gguf
      cognitivecomputations/DeepSeek-V3-0324-AWQ
      comfyanonymous/flux_text_encoders
      deepseek-ai/DeepSeek-Prover-V2-671B
      deepseek-ai/DeepSeek-R1
      deepseek-ai/DeepSeek-R1-0528
      deepseek-ai/DeepSeek-R1-Distill-Llama-70B
      deepseek-ai/DeepSeek-R1-Distill-Llama-8B
      deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
      deepseek-ai/DeepSeek-R1-Distill-Qwen-14B
      deepseek-ai/DeepSeek-R1-Distill-Qwen-32B
      deepseek-ai/DeepSeek-R1-Distill-Qwen-7B
      deepseek-ai/DeepSeek-R1-Zero
      deepseek-ai/DeepSeek-V3
      deepseek-ai/DeepSeek-V3-0324
      deepseek-ai/DeepSeek-V3-Base
      deepseek-ai/Janus-Pro-7B
      deepseek-ai/deepseek-r1-distill-qwen-1.5b
      deepseek-ai/deepseek-r1-distill-qwen-7b
      deepseek-ai/deepseek-vl2-tiny
      echo840/MonkeyOCR
      eugenesiow/Div2k
      facebook/esm2_t48_15B_UR50D
      gaia-benchmark/GAIA
      goodfellowliu/Flickr2K
      google-bert/bert-base-uncased
      google/flan-t5-xxl
      google/gemma-3-12b-it
      google/gemma-3-1b-it
      google/gemma-3-27b-it
      google/gemma-3-4b-it
      google/medgemma-27b-text-it
      google/medgemma-4b-it
      google/siglip-so400m-patch14-384
      google/t5-v1_1-xxl
      google/vit-base-patch16-224
      hf-internal-testing/llama-tokenizer
      hongchi/wildrgbd
      hongchi/wildrgbd
      huxueyu/0.5B_en_train_16_20250129-134441
      huxueyu/0.5B_en_train_16_zh_train_16_fr_train_16_es_train_16_20250129-162020
      huxueyu/0.5B_en_train_1_20250129-135620
      huxueyu/0.5B_en_train_1_es_train_16_20250130-042204
      huxueyu/0.5B_en_train_1_es_train_1_20250130-054545
      huxueyu/0.5B_en_train_1_es_train_256_20250130-030948
      huxueyu/0.5B_en_train_1_es_train_4_20250130-050028
      huxueyu/0.5B_en_train_1_es_train_64_20250130-034602
      huxueyu/0.5B_en_train_1_fr_train_16_20250130-003217
      huxueyu/0.5B_en_train_1_fr_train_1_20250130-015514
      huxueyu/0.5B_en_train_1_fr_train_256_20250129-232036
      huxueyu/0.5B_en_train_1_fr_train_4_20250130-011017
      huxueyu/0.5B_en_train_1_fr_train_64_20250129-235612
      huxueyu/0.5B_en_train_1_zh_train_16_20250129-204850
      huxueyu/0.5B_en_train_1_zh_train_1_20250129-221038
      huxueyu/0.5B_en_train_1_zh_train_1_fr_train_1_es_train_1_20250129-170723
      huxueyu/0.5B_en_train_1_zh_train_256_20250129-193633
      huxueyu/0.5B_en_train_1_zh_train_4_20250129-212622
      huxueyu/0.5B_en_train_1_zh_train_64_20250129-201242
      huxueyu/0.5B_en_train_256_20250129-134208
      huxueyu/0.5B_en_train_256_zh_train_256_fr_train_256_es_train_256_20250129-161615
      huxueyu/0.5B_en_train_4_20250129-134723
      huxueyu/0.5B_en_train_4_zh_train_4_fr_train_4_es_train_4_20250129-162944
      huxueyu/0.5B_en_train_64_20250129-134325
      huxueyu/0.5B_en_train_64_zh_train_64_fr_train_64_es_train_64_20250129-161732
      huxueyu/0.5B_es_train_16_20250130-122336
      huxueyu/0.5B_es_train_1_20250130-123637
      huxueyu/0.5B_es_train_256_20250130-122107
      huxueyu/0.5B_es_train_4_20250130-122634
      huxueyu/0.5B_es_train_64_20250130-122217
      huxueyu/0.5B_fr_train_16_20250129-152356
      huxueyu/0.5B_fr_train_1_20250129-153638
      huxueyu/0.5B_fr_train_256_20250129-152136
      huxueyu/0.5B_fr_train_4_20250129-152648
      huxueyu/0.5B_fr_train_64_20250129-152238
      huxueyu/0.5B_zh_train_16_20250129-143442
      huxueyu/0.5B_zh_train_1_20250129-144611
      huxueyu/0.5B_zh_train_256_20250129-143226
      huxueyu/0.5B_zh_train_4_20250129-143719
      huxueyu/0.5B_zh_train_64_20250129-143327
      huxueyu/3B_fr_train_1_20250131-173250
      internlm/internlm2-chat-7b
      jinaai/jina-clip-v2
      juaner0211/Animal_Crossing_style_flux_lora
      laion/CLIP-ViT-bigG-14-laion2B-39B-b160k
      latent-action-pretraining/LAPA-7B-openx
      leapfusion-image2vid-test/image2vid-960x544
      leptonai/EAGLE-Llama-3.1-70B-Instruct
      leptonai/EAGLE-Llama-3.1-8B-Instruct
      lerobot/aloha_sim_insertion_human
      lerobot/diffusion_pusht
      lerobot/pusht
      lingshu-medical-mllm/Lingshu-32B
      lingshu-medical-mllm/Lingshu-7B
      liuqingquan/sd35_clip_l
      llava-hf/llava-interleave-qwen-0.5b-hf
      llava-hf/llava-v1.6-mistral-7b-hf
      lokCX/4x-Ultrasharp
      meta-llama/Llama-2-7b
      meta-llama/Llama-3.1-70B-Instruct
      meta-llama/Llama-3.1-8B-Instruct
      meta-llama/Llama-3.2-11B-Vision-Instruct
      meta-llama/Llama-3.3-70B-Instruct
      meta-llama/Llama-4-Scout-17B-16E
      meta-llama/Llama-4-Scout-17B-16E-Instruct
      meta-llama/Meta-Llama-3-8B
      meta-llama/Meta-Llama-3-8B-Instruct
      microsoft/Phi-4-multimodal-instruct
      moonshotai/Kimi-Audio-7B-Instruct
      mtoan65/ATLAS_nnUNetv2
      nari-labs/Dia-1.6B
      nvidia/Llama-3_1-Nemotron-Ultra-253B-v1
      omlab/VLM-R1
      open-r1/OpenR1-Math-220k
      open-thoughts/OpenThinker-7B
      openai/clip-vit-base-patch32
      openai/clip-vit-large-patch14
      openai/whisper-large
      openai/whisper-tiny
      openbmb/MiniCPM-V-2_6
      openbmb/MiniCPM-o-2_6
      openbmb/MiniCPM3-4B
      openbmb/RLAIF-V-12B
      openvla/modified_libero_rlds
      openvla/openvla-7b
      perplexity-ai/r1-1776
      qihoo360/Light-R1-32B-DS
      qihoo360/Light-R1-7B-DS
      qwbu/univla-7b
      qwbu/univla-latent-action-model
      qwen/Qwen1.5-1.8B-Chat
      robotics-diffusion-transformer/rdt-1b
      runwayml/stable-diffusion-v1-5
      stabilityai/sdxl-turbo
      stabilityai/stable-diffusion-3.5-large
      stabilityai/stable-video-diffusion-img2vid-xt
      stabilityai/stable-video-diffusion-img2vid-xt-1-1
      tencent/DepthCrafter
      tencent/HunyuanVideo
      unsloth/DeepSeek-R1-GGUF
      vidore/colpali-v1.2
      vidore/colpaligemma-3b-pt-448-base
      vidore/colqwen2.5-base
      vidore/colqwen2.5-v0.2
      waanqii/SMPLest-X
      wtcherr/unsplash_10k_canny
      x-humanoid-robomind/RoboMIND
      xlabs-ai/xflux_text_encoders
      xtuner/llava-llama-3-8b-v1_1-transformers
      yentinglin/aime_2025
      yulan-team/YuLan-Mini
      zheng95z/rgb-to-x
      zhzhen23/DynVQA
      zixianma/mnms

   </details>

>å¦‚æœ‰å…¶ä»–æ¨¡å‹éœ€æ±‚ï¼Œå¯è”ç³»å®¢æœæ·»åŠ è‡³ç¼“å­˜ä¸­~

3. ç¡®ä¿å·²å®‰è£… huggingface_hub åº“çš„æƒ…å†µä¸‹ï¼Œä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ä¸‹è½½æ¨¡å‹ï¼Œä¸‹è½½å¹³å‡é€Ÿåº¦å¯è¾¾60MB/sï¼š
```
huggingface-cli download --resume-download Qwen/Qwen2.5-1.5B-Instruct --local-dir Qwen/Qwen2.5-1.5B-Instruct
```

   ![model1](./pic/model1.png)



# å¿«é€Ÿå¼€å§‹

>AladdinEduçš„ä½¿ç”¨ä¸»è¦åˆ†ä¸ºä¸‰æ­¥ï¼Œworkshopåˆ›å»º > ç¯å¢ƒé…ç½® > GPUè°ƒç”¨ï¼Œä»¥ä¸‹å†…å®¹å°†å›´ç»•æ­¤æµç¨‹å±•å¼€ã€‚

## æ’ä»¶åˆå§‹åŒ–

_æœ¬èŠ‚é¢„è®¡å®Œæˆæ—¶é—´ï¼š2min_

### æ’ä»¶å®‰è£…
ä»¥VSCodeç‰ˆæœ¬ä¸ºä¾‹

1. åœ¨æ‰©å±•ä¸­æœç´¢Aladdinï¼Œç‚¹å‡»å®‰è£…ï¼š

   ![install1](./pic/vs1.png)

2. å®‰è£…å®Œæˆåå¯åœ¨æ´»åŠ¨æ çœ‹åˆ°Aladdinæ’ä»¶å›¾æ ‡ï¼Œå®‰è£…æˆåŠŸï¼š

   ![install2](./pic/vs2.png)

### è´¦å·ç™»å½•
ä»¥VSCodeç‰ˆæœ¬ä¸ºä¾‹

1. ç‚¹å‡»Aladdinæ’ä»¶å›¾æ ‡ï¼Œé€‰æ‹©Login Personal Accountï¼Œå¼¹çª—åé€‰æ‹©â€œæ‰“å¼€â€å¤–éƒ¨ç½‘ç«™ï¼ˆAladdinEduå¹³å°ï¼‰ï¼š

   ![login1](./pic/login1.png)

2. åœ¨AladdinEduå¹³å°ä¸­ä½¿ç”¨æ‰‹æœºå·æˆ–è´¦å·å¯†ç ç™»å½•ï¼Œé¦–æ¬¡ä½¿ç”¨è€…è¯·å…ˆæ³¨å†Œï¼š

   ![login2](./pic/login2.png)

3. ç™»å½•æˆåŠŸåç‚¹å‡»â€œç‚¹å‡»è¿”å›VSCodeâ€ï¼Œç­‰å¾…è¿”å›VSCodeï¼ˆå¦‚æœªè‡ªåŠ¨è·³è½¬ï¼Œè¯·**æ‰‹åŠ¨**è¿”å›VSCodeï¼‰ã€‚æ­¤æ—¶VSCodeä¸­å‡ºç°å¼¹çª—ï¼Œé€‰æ‹©â€œæ‰“å¼€â€æ­¤URLï¼Œæç¤ºç™»å½•æˆåŠŸï¼š

   ![login3](./pic/login3.png)

   ![login4](./pic/login4.png)

## workshopåˆ›å»º

_æœ¬èŠ‚é¢„è®¡å®Œæˆæ—¶é—´ï¼š3.5min_

>Stopæ—¶workshopä¸­çš„æ•°æ®ï¼ˆåŒ…æ‹¬ç¯å¢ƒï¼‰å°†**å…¨éƒ¨ä¿å­˜**ï¼Œå› æ­¤é‡æ–°Openåæ— éœ€å†æ¬¡é…ç½®å’Œä¸Šä¼ æ•°æ®ã€‚æ€»ä¹‹ï¼Œworkshopåœ¨ï¼Œæ•°æ®åœ¨ã€‚ä½†æ˜¯ï¼Œè‡ªå½“å‰ç®—åŠ›å¥—é¤å¤±æ•ˆèµ·ï¼Œè‹¥15æ—¥å†…æœªç™»å½•è¿‡AladdinEduå¹³å°ï¼Œå­˜å‚¨å°†ä¼šè¢«é‡Šæ”¾ã€‚

workshopä¸ºAladdinæ’ä»¶çš„ç¼–ç åŒºï¼Œå¯åœ¨æœ¬åœ°VSCodeä¸­è¿æ¥è¿œç¨‹æœåŠ¡å™¨ã€‚

1. åœ¨workshopèœå•æ ä¸­ç‚¹å‡» **+**ï¼Œæ–°å»ºworkshopï¼š

   ![workshop1](./pic/workshop1.png)

2. å¡«å†™workshopåç§°ï¼Œé€‰æ‹©åŸºç¡€é•œåƒä¸èµ„æºï¼ˆæ¨èé€‰æ‹©â€œCPU:2 MEM:8Gâ€ï¼‰ï¼š

   ![workshop2](./pic/workshop2.png)

- workshopå¯åŠ¨å‚æ•°ä»‹ç»

| å‚æ•°åç§°       | è¯´æ˜                                                                 | å¤‡æ³¨                                                                 |
|----------------|----------------------------------------------------------------------|----------------------------------------------------------------------|
| **Environment** | å½“å‰workshopä½¿ç”¨çš„å®¹å™¨é•œåƒ                                         | é€šå¸¸åŒ…å«é¢„è£…è½¯ä»¶å’ŒåŸºç¡€è¿è¡Œç¯å¢ƒ                                       |
| **Resource**    | å½“å‰workshopå¯åŠ¨æ—¶åˆ†é…åˆ°çš„CPUå’Œå†…å­˜èµ„æº                                    | è¿™äº›èµ„æºä¸GPUè¿è¡Œæ—¶æ˜¯å…±äº«çš„ï¼Œ<br>GPUèµ„æºè¯¦æƒ…è¯·æŸ¥çœ‹[GPUè°ƒç”¨](#gpuè°ƒç”¨) |
| **ENV**        | å½“å‰workshopè¿è¡Œæ—¶çš„ç¯å¢ƒå˜é‡                                         | å¯ç”¨äºé…ç½®åº”ç”¨å‚æ•°ã€APIå¯†é’¥ç­‰æ•æ„Ÿä¿¡æ¯                                |

- é•œåƒä»‹ç»å¯æŸ¥çœ‹[é…ç½®ç¯å¢ƒ](#é…ç½®ç¯å¢ƒ)

3. ç‚¹å‡»æäº¤åä¼šå‡ºç°æ’ä»¶çš„çŠ¶æ€æç¤ºï¼Œé…ç½®é¢„è®¡åœ¨2minå·¦å³å®Œæˆï¼Œæç¤ºç”±â€œWorkshop is waiting for creating.â€å˜ä¸ºâ€œWorkshop is created.â€ï¼š

   ![workshop3](./pic/workshop3-2.png)

4. æ­¤æ—¶ä¼šå¼¹å‡ºä¸€ä¸ªæ–°çª—å£ï¼ˆåæ–‡ç»Ÿç§°ä¸º**è¿œç«¯é¡µé¢**ï¼‰ï¼Œé€‰æ‹©"Linux"ï¼Œä¹‹åè¿œç«¯é¡µé¢ä¸­å°†è‡ªåŠ¨å®‰è£…ç›¸å…³æ’ä»¶ï¼š

   ![workshop4](./pic/workshop4.png)

5. ç­‰å¾…è¿œç«¯é¡µé¢ä¸­å‡ºç°Aladdinæ’ä»¶å›¾æ ‡ï¼Œworkshopåˆ›å»ºå®Œæˆï¼š

   ![workshop5](./pic/workshop5.png)

>è‹¥æ‚¨3å¤©ä»¥ä¸Šæœªè°ƒç”¨GPUï¼Œworkshopå°†ä¼š**è‡ªåŠ¨åœæ­¢**ã€‚ä½†è¯·ä¸ç”¨æ‹…å¿ƒï¼Œworkshopåœæ­¢ä¸ä¼šå½±å“å…¶ä¸­è¿è¡Œçš„GPUä»»åŠ¡ï¼Œä¸‹æ¬¡ä½¿ç”¨é‡æ–°å¯åŠ¨å³å¯~

## è¿è¡ŒDemo

_æœ¬èŠ‚é¢„è®¡å®Œæˆæ—¶é—´ï¼šçº¦1min_
_ä»¥ä¸‹æ“ä½œå‡åœ¨è¿œç«¯é¡µé¢ä¸­è¿›è¡Œã€‚_

<!-- ç”±äºç›®å‰ä¿å­˜é•œåƒåŠŸèƒ½æš‚æœªä¸Šçº¿ï¼Œç›´æ¥å°†åŒ…è£…åœ¨é•œåƒä¸­å°†æ— æ³•æ­£å¸¸ä½¿ç”¨ã€‚**å› æ­¤ï¼Œå¦‚éœ€è‡ªå®šä¹‰å®‰è£…pythonåŒ…ï¼Œå‡éœ€ä»é›¶å¼€å§‹é…ç½®ç¯å¢ƒ**ã€‚
>æ³¨ï¼šå¼ºçƒˆæ¨èæŒ‰ç…§æœ¬æ–‡è¯´æ˜ï¼Œä½¿ç”¨minicondaåšç¯å¢ƒé…ç½®ã€‚

1. workshopåˆ›å»ºæˆåŠŸåï¼Œè¿›å…¥è¿œç«¯é¡µé¢ï¼Œé€‰æ‹©æ‰“å¼€/rootç›®å½•ï¼š

   ![conda1](./pic/conda1.png)

2. æ–°å»ºç»ˆç«¯ï¼Œåœ¨ç»ˆç«¯ä¸­å®‰è£…minicondaï¼Œå¹¶ç¡®è®¤**å®‰è£…åœ¨/rootç›®å½•**ä¸‹ï¼š

   ![conda2](./pic/conda2.png)

   ![conda3](./pic/conda3.png)

- Condaé…ç½®æ–¹æ³•

```bash
# ä¸‹è½½æœ€æ–°ç‰ˆ Miniconda (Linux 64ä½)
curl -L -O https://mirrors.tuna.tsinghua.edu.cn/anaconda/miniconda/Miniconda3-latest-Linux-x86_64.sh
# è¿è¡Œå®‰è£…è„šæœ¬
bash Miniconda3-latest-Linux-x86_64.sh
# å®‰è£…æ—¶You can undo this by running `conda init --reverse $SHELL`?
# æ­¤é¡¹å¿…é¡»é€‰æ‹©Yes,å®‰è£…å®Œæˆåé‡å¯ç»ˆç«¯condaå‘½ä»¤æ‰èƒ½ç”Ÿæ•ˆ~

# éªŒè¯å®‰è£…
conda --version
# åº”è¯¥æ˜¾ç¤ºç±»ä¼¼ï¼šconda 25.1.1

# æ·»åŠ æ¸…å conda æº
conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/
conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/
conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/
# æ˜¾ç¤ºé€šé“URL
conda config --set show_channel_urls yes
# è®¾ç½® pip ä½¿ç”¨æ¸…åæº
pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple

```
3. æˆåŠŸå®‰è£…minicondaåï¼Œéœ€é…ç½®pythonè§£é‡Šå™¨â€”â€”æ–°å»ºä¸€ä¸ªpythonæ–‡ä»¶ï¼Œç‚¹å‡»è¿œç«¯é¡µé¢å³ä¸‹è§’çš„pythonç‰ˆæœ¬å·ï¼Œåˆ‡æ¢åˆ°condaç¯å¢ƒä¸­çš„pythonï¼š

æˆ–ä½¿ç”¨`Ctrl+Shift+P`å¿«æ·é”®æ‰“å¼€å‘½ä»¤çª—å£ï¼Œè¾“å…¥"Select Interpreter"ï¼Œæ›´æ¢pythonè§£é‡Šå™¨ã€‚
>**é‡è¦ â—**ï¼šå¦‚ä¸åˆ‡æ¢ï¼Œè°ƒç”¨GPUæ—¶å°†æ— æ³•å¤ç”¨é…ç½®çš„ç¯å¢ƒï¼Œå‡ºç°æ‰¾ä¸åˆ°å·²å®‰è£…åŒ…çš„æŠ¥é”™ï¼

   ![conda5](./pic/conda5.png)

4. è¿œç«¯é¡µé¢å³ä¸‹è§’çš„ç‰ˆæœ¬å·å‡ºç°condaç¯å¢ƒåï¼Œç¯å¢ƒåˆ‡æ¢æˆåŠŸï¼š

   ![conda4](./pic/conda4.png)

5. æ¥ç€å®‰è£…torchï¼Œæ¨èå®‰è£…12.4ç‰ˆä»¥é€‚é…GPUï¼š
>é…ç½®ç§‘å­¦ä¸Šç½‘åå°†æ˜¾è‘—æå‡ä¸‹è½½å®‰è£…é€Ÿåº¦ï¼Œå…·ä½“æ­¥éª¤å‚è€ƒ[å­¦æœ¯èµ„æºåŠ é€Ÿ](#å­¦æœ¯èµ„æºåŠ é€Ÿ)ã€‚

```bash
#å®‰è£…cuda 12.4
pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124
``` -->

1. æ‰“å¼€/rootç›®å½•æ–‡ä»¶å¤¹ï¼Œæ–°å»ºtest.pyæ–‡ä»¶ï¼Œå°†æµ‹è¯•ä»£ç å¤åˆ¶åˆ°æ–‡ä»¶ä¸­ï¼Œ**åœ¨ä»£ç åŒºæˆ–å¯¹æ–‡ä»¶å³å‡»**ï¼Œé€‰æ‹©GPU RUNè¿è¡Œï¼š
   ![workshop0](./pic/workshop0.png)
   ![conda6](./pic/conda6.png)
>ä½¿ç”¨ä»¥ä¸‹ä»£ç æµ‹è¯•cudaæ˜¯å¦å®‰è£…æˆåŠŸï¼Œä»¥åŠæ˜¯å¦ä¸å½“å‰ç¯å¢ƒGPUå…¼å®¹ï¼š

```python
import torch
import time

def test_cuda_availability():
    print("\n======= CUDA æµ‹è¯• =======")
    # æ£€æŸ¥ CUDA æ˜¯å¦å¯ç”¨
    cuda_available = torch.cuda.is_available()
    print(f"PyTorch CUDA å¯ç”¨: {'âœ…æ˜¯' if cuda_available else 'âŒå¦'}")

    if cuda_available:
        # æ‰“å° CUDA ç‰ˆæœ¬å’Œè®¾å¤‡ä¿¡æ¯
        print(f"PyTorch CUDA ç‰ˆæœ¬: {torch.version.cuda}")
        print(f"å½“å‰ GPU è®¾å¤‡: {torch.cuda.get_device_name(0)}")
        print(f"GPU æ•°é‡: {torch.cuda.device_count()}")
    else:
        print("âš ï¸ è¯·æ£€æŸ¥ CUDA å’Œ PyTorch æ˜¯å¦å®‰è£…æ­£ç¡®ï¼")
    print("========================\n")

def test_gpu_speed():
    print("\n======= GPU é€Ÿåº¦æµ‹è¯• =======")
    # åˆ›å»ºä¸€ä¸ªå¤§å‹å¼ é‡
    x = torch.randn(10000, 10000)
    
    # CPU è®¡ç®—
    start_time = time.time()
    x_cpu = x * x
    cpu_time = time.time() - start_time
    print(f"CPU è®¡ç®—æ—¶é—´: {cpu_time:.4f} ç§’")

    if torch.cuda.is_available():
        # ç§»åŠ¨åˆ° GPU è®¡ç®—
        x_gpu = x.to('cuda')
        start_time = time.time()
        x_gpu = x_gpu * x_gpu
        torch.cuda.synchronize()  # ç¡®ä¿ GPU è®¡ç®—å®Œæˆ
        gpu_time = time.time() - start_time
        print(f"GPU è®¡ç®—æ—¶é—´: {gpu_time:.4f} ç§’")
        print(f"GPU æ¯” CPU å¿«: {cpu_time / gpu_time:.1f} å€")
    else:
        print("âš ï¸ GPU ä¸å¯ç”¨ï¼Œè·³è¿‡æµ‹è¯•")
    print("==========================\n")

def test_training():
    print("\n======= ç®€å•è®­ç»ƒæµ‹è¯• =======")
    # å®šä¹‰ä¸€ä¸ªæç®€ç¥ç»ç½‘ç»œ
    model = torch.nn.Sequential(
        torch.nn.Linear(10, 100),
        torch.nn.ReLU(),
        torch.nn.Linear(100, 1)
    )
    
    # å¦‚æœæœ‰ GPUï¼Œå°†æ¨¡å‹å’Œæ•°æ®ç§»åˆ° GPU
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    model = model.to(device)
    print(f"ä½¿ç”¨è®¾å¤‡: {device.upper()}")

    # æ¨¡æ‹Ÿæ•°æ®
    X = torch.randn(1000, 10).to(device)
    y = torch.randn(1000, 1).to(device)

    # è®­ç»ƒå¾ªç¯
    optimizer = torch.optim.SGD(model.parameters(), lr=0.01)
    start_time = time.time()
    for epoch in range(5):
        optimizer.zero_grad()
        output = model(X)
        loss = torch.nn.functional.mse_loss(output, y)
        loss.backward()
        optimizer.step()
        print(f"Epoch {epoch + 1}, Loss: {loss.item():.4f}")
    
    total_time = time.time() - start_time
    print(f"æ€»è®­ç»ƒæ—¶é—´: {total_time:.2f} ç§’")
    print("==========================\n")

if __name__ == "__main__":
    test_cuda_availability()
    test_gpu_speed()
    test_training()
```


2. ä¿®æ”¹å¯åŠ¨é€‰é¡¹ï¼šç¯å¢ƒé€‰æ‹©ä¸ºtorchï¼Œèµ„æºé€‰æ‹©ä¸ºGPUï¼Œpythonè§£é‡Šå™¨æŒ‰éœ€é€‰æ‹©ï¼Œå…¶ä½™ä¸å˜ã€‚æäº¤è¿è¡Œï¼š

   ![conda6](./pic/conda6-1.png)
> è‹¥é€‰æ‹©Save as configurationä¿å­˜å½“å‰å‚æ•°è®¾ç½®ï¼Œä¹‹åè°ƒç”¨GPUæ—¶å°†å¼¹å‡ºQuick GPU Runçª—å£ï¼Œåˆ—å‡ºå†…å®¹ä¸ºä¿å­˜çš„Configurationã€‚æ‚¨å¯ç›´æ¥é€‰ç”¨ä»¥å¿«æ·å¯ç”¨GPU Runï¼Œæˆ–é€šè¿‡+ New Createé‡æ–°è®¾ç½®å‚æ•°ã€‚
>    ![conda6](./pic/conda6-2.png)

è¾“å‡ºå†…å®¹æ¡ˆä¾‹ï¼š
```
======= CUDA æµ‹è¯• =======
 PyTorch CUDA å¯ç”¨: âœ…æ˜¯
 PyTorch CUDA ç‰ˆæœ¬: 12.4
 å½“å‰ GPU è®¾å¤‡: [ä½ é€‰æ‹©çš„æ˜¾å¡]
 GPU æ•°é‡: 1
========================

======= GPU é€Ÿåº¦æµ‹è¯• =======
 CPU è®¡ç®—æ—¶é—´: 0.1339 ç§’
 GPU è®¡ç®—æ—¶é—´: 0.0078 ç§’
 GPU æ¯” CPU å¿«: 17.3 å€
==========================

======= ç®€å•è®­ç»ƒæµ‹è¯• =======
ä½¿ç”¨è®¾å¤‡: CUDA
Epoch 1, Loss: 1.0850
Epoch 2, Loss: 1.0827
Epoch 3, Loss: 1.0805
Epoch 4, Loss: 1.0784
Epoch 5, Loss: 1.0763
æ€»è®­ç»ƒæ—¶é—´: 0.17 ç§’
==========================
 
```

# é…ç½®ç¯å¢ƒ

## æ¦‚è¦

AladdinEduå†…ç½®äº†éƒ¨åˆ†å…¬å…±é•œåƒï¼Œå¯åŠ¨workshopæ—¶é€‰æ‹©å…¬å…±é•œåƒå°±ä¼šè‡ªå¸¦ç›¸åº”æ¡†æ¶çš„è½¯ä»¶ã€‚å¦‚æœè‡ªå¸¦çš„æ¡†æ¶ç‰ˆæœ¬æˆ–Pythonç‰ˆæœ¬ä¸æ»¡è¶³éœ€æ±‚ï¼Œè¯·è‡ªè¡Œé…ç½®å…¶ä»–ç‰ˆæœ¬çš„æ¡†æ¶æˆ–å°è¯•Pythonæ–¹æ³•ã€‚

1. å…¬å…±é•œåƒ

| é•œåƒç±»å‹ | ç‰ˆæœ¬æ ‡ç­¾    | åŒ…å«å†…å®¹                                                                 |
|:--------:|:-----------:|:------------------------------------------------------------------------|
| torch    | 2.5.1-cu124 | **æ ¸å¿ƒåŒ…:**<br>`torch==2.5.1` `torchvision==0.20.1` `torchaudio==2.5.1` `cuda==12.4`<br>**é™„åŠ åŒ…:**<br>`datasets` `transformers` `scikit-learn` `peft` `tiktoken` `blobfile` `sentencepiece` `protobuf` `deepspeed` |
| torch    | 2.6.0-cu124 | **æ ¸å¿ƒåŒ…:**<br>`torch==2.6.0` `torchvision==0.21.0` `torchaudio==2.6.0` `cuda==12.4`<br>**é™„åŠ åŒ…:**<br>åŒ 2.5.1 ç‰ˆæœ¬ |
| jupyter-lab | 4.4.2 | **æ ¸å¿ƒåŒ…:**<br>`jupyterlab==4.4.2` `torch==2.5.1+cu124` `cuda==12.4` |
|llama-factory | v0.9.3.dev0-cuda12.4-cudnn9-devel |**æ ¸å¿ƒåŒ…:** <br>`llamafactory==0.9.3` `peft==0.15.1` `trl==0.9.6`<br>`accelerate==1.6.0` `transformers==4.51.3`<br>`torch==2.7.0` `cuda==12.6` | 
|llama-factory | v0.9.3.dev0-cuda12.1-cudnn9-devel |**æ ¸å¿ƒåŒ…:** <br>`llamafactory==0.9.3` `peft==0.15.1` `trl==0.9.6`<br>`accelerate==1.6.0` `transformers==4.51.3`<br>`torch==2.7.0` `cuda==12.1` | 
|python | 3.10/3.11/3.12/3.13 | çº¯å‡€Pythonç¯å¢ƒ |
| ubuntu   | 22.04       | çº¯å‡€ Ubuntu 22.04 ç³»ç»Ÿ                                                  |
> æ³¨ï¼šjupyter-labå’Œllama-factoryå‡å·²é…condaã€‚å¦‚æ‚¨é€‰ç”¨jupyter-labå’Œllam-factoryä½œä¸ºworkshopçš„åŸºç¡€é•œåƒï¼Œåç»­é…ç½®ç¯å¢ƒæ—¶æ— éœ€å†æ‰‹åŠ¨å®‰è£…condaã€‚

2. å®‰è£…å…¶ä»–ç‰ˆæœ¬çš„Pythonï¼š æ¨èä½¿ç”¨Minicondaåˆ›å»ºå…¶ä»–ç‰ˆæœ¬çš„Pythonè™šæ‹Ÿç¯å¢ƒ

```bash
# æ„å»ºä¸€ä¸ªè™šæ‹Ÿç¯å¢ƒåä¸ºï¼šmyenvï¼ŒPythonç‰ˆæœ¬ä¸º3.7
conda create -n myenv python=3.7    

# æ›´æ–°bashrcä¸­çš„ç¯å¢ƒå˜é‡
conda init bash && source /root/.bashrc
# åˆ‡æ¢åˆ°åˆ›å»ºçš„è™šæ‹Ÿç¯å¢ƒï¼šmy-env
conda activate myenv

# éªŒè¯
python --version
```

3. å®‰è£…PyTorchï¼š [å‚è€ƒé“¾æ¥](https://pytorch.org/get-started/previous-versions/)

>â— æ³¨æ„ï¼š
1ï¸âƒ£ é€šè¿‡Torchå®˜æ–¹çš„condaå®‰è£…å‘½ä»¤ï¼Œåœ¨å›½å†…å®‰è£…çš„condaä¸€èˆ¬ä¸ºécudaç‰ˆæœ¬ï¼Œè€Œæ˜¯cpuç‰ˆæœ¬ï¼ˆæœ‰bugï¼‰ï¼Œå› æ­¤æ¨èç”¨pipå®‰è£…ã€‚å¹¶ä¸”ï¼Œå¦‚æœä½¿ç”¨torchå®˜æ–¹çš„pipå‘½ä»¤ï¼Œå»æ‰-f/--index-urlå‚æ•°ï¼Œè¿™æ ·å¯ä»¥èµ°å›½å†…çš„pipæºï¼Œé€Ÿåº¦æ›´å¿«ï¼›
2ï¸âƒ£ å¹³å°ä¸­ç›®å‰æ‰€æä¾›æ˜¾å¡æ”¯æŒçš„æœ€ä½cudaç‰ˆæœ¬ä¸º11.8ï¼Œè¿‡ä½ç‰ˆæœ¬å¯èƒ½ä¼šå¯¼è‡´è®¡ç®—æ€§èƒ½æŸå¤±ã€‚

4. å®‰è£…TensorFlowï¼š [å‚è€ƒé“¾æ¥](https://www.tensorflow.org/install/pip?hl=zh-cn)

- **æ¨èçš„ä½¿ç”¨å§¿åŠ¿**
  ï¼ˆ1ï¼‰å¦‚æœå¹³å°å†…ç½®çš„å…¬å…±é•œåƒä¸­æœ‰æ‚¨éœ€è¦çš„Torchã€TensorFlowç­‰æ¡†æ¶çš„ç›¸åº”ç‰ˆæœ¬ï¼Œé¦–é€‰å…¬å…±é•œåƒã€‚
  ï¼ˆ2ï¼‰å¦‚æœä»¥ä¸Šæ¡ä»¶éƒ½ä¸æ»¡è¶³ï¼Œæ¨èä½¿ç”¨Ubuntuç³»ç»Ÿï¼Œå¹¶è‡ªè¡Œå®‰è£…minicondaè¿›è¡Œç¯å¢ƒé…ç½®ã€‚

## ç§æœ‰é•œåƒ
AladdinEduæ”¯æŒä¿å­˜ç§æœ‰é•œåƒï¼Œåˆ†ä¸ºä¸¤ç§æ–¹å¼ï¼šæœ¬åœ°ä¸Šä¼ ç§æœ‰é•œåƒã€ä¿å­˜workshopç¯å¢ƒé•œåƒã€‚ç§æœ‰é•œåƒå¯åœ¨æ§åˆ¶å°çš„ç§æœ‰é•œåƒä»“åº“ã€æœ¬åœ°VSCodeçš„ENVIRONMENTSä¸­æŸ¥çœ‹ã€‚

### ä¸Šä¼ ç§æœ‰é•œåƒ
1. æ‰“å¼€ç”µè„‘ç»ˆç«¯ï¼Œé€æ¡è¾“å…¥ä»¥ä¸‹å‘½ä»¤ï¼ˆä»¥python3ä¸ºä¾‹ï¼‰ï¼Œæ¨é€æˆåŠŸåå³æˆåŠŸåœ¨ç§æœ‰é•œåƒä»“åº“ä¸­æ–°å¢é•œåƒï¼š
```python
#Â ç™»å½•
dockerÂ loginÂ registry.hd-01.alayanew.com:8443
#Â æ‹‰å–é•œåƒ
dockerÂ pullÂ m.daocloud.io/docker.io/library/python:3
#Â é•œåƒtagé‡å‘½å
dockerÂ tagÂ m.daocloud.io/docker.io/library/pythonÂ registry.hd-01.alayanew.com:8443/aladdinedu-e3fadb18-a994-470f-9a59-dde816718791/python:3
#Â æ¨é€é•œåƒ
dockerÂ pushÂ registry.hd-01.alayanew.com:8443/aladdinedu-e3fadb18-a994-470f-9a59-dde816718791/python:3
```

> ç”¨æˆ·åã€å¯†ç åœ¨æ§åˆ¶å°çš„ç§æœ‰é•œåƒä»“åº“é¡µæŸ¥çœ‹

   ![image](./pic/image.png)
2. åœ¨VSCodeä¸­ç™»å½•Aladdinï¼Œå¹¶åœ¨Registryä¸­å¡«å…¥ç§æœ‰é•œåƒä»“åº“çš„ç”¨æˆ·åã€å¯†ç ï¼Œç™»å½•ç§æœ‰é•œåƒä»“åº“ï¼š
   ![login12](./pic/login12.png)
3. æ­¤æ—¶ï¼ŒENVIRONMENTSä¸­å¯æŸ¥çœ‹ç§æœ‰é•œåƒä»“åº“ï¼Œå…¶ä¸­åˆ—å‡ºäº†ä¸Šä¼ çš„ç§æœ‰é•œåƒï¼Œåœ¨workshopã€GPUé…ç½®é¡µä¸­å¯ç›´æ¥é€‰æ‹©ä½¿ç”¨ã€‚
   ![image1](./pic/image1.png)

### ä¿å­˜workshopç¯å¢ƒ

å¦‚éœ€å°†åœ¨workshopä¸­ä½¿ç”¨çš„ç¯å¢ƒä¿å­˜åˆ°ç§æœ‰é•œåƒä¸­ï¼Œå¯æŒ‰å¦‚ä¸‹æ­¥éª¤æ“ä½œã€‚<span style="color: red; font-weight: bold">éœ€æ³¨æ„ï¼Œä»¥ä¸‹æ­¥éª¤è¦æ±‚ workshop ä¸º running çŠ¶æ€ã€‚<Span/>

1. **å¯åŠ¨workshop**ï¼Œ å³é”®é€‰æ‹©â€œSave Envâ€ï¼š
   ![saveEnv](./pic/SaveEnv.png)
2. é€‰æ‹©ç§æœ‰é•œåƒä»“åº“ï¼Œå›è½¦ï¼š
   ![saveEnv1](./pic/saveEnv1.png)
3. è¾“å…¥è¦ä¿å­˜çš„workshopç¯å¢ƒåï¼Œå›è½¦ï¼š
   ![saveEnv2](./pic/saveEnv2.png)
4. è¾“å…¥tagï¼Œå›è½¦ï¼Œç­‰å¾…ä¿å­˜ï¼š
   ![saveEnv3](./pic/saveEnv3.png)
5. é€‰æ‹©yesï¼Œæ›´æ–°å½“å‰workshopé•œåƒï¼š
   ![saveEnv4](./pic/saveEnv4.png)
  > å¦‚æœé€‰æ‹©noï¼Œä¿å­˜çš„workshopç¯å¢ƒä¸ä¼šä½œç”¨äºå½“å‰workshopã€‚
6. æ›´æ–°æˆåŠŸåï¼Œç§æœ‰é•œåƒä»“åº“ä¸­å³ä¼šå­˜æœ‰è¯¥ç¯å¢ƒï¼Œæ­¤æ—¶åœ¨workshopã€GPUé…ç½®é¡µä¸­å¯é€‰æ‹©ä½¿ç”¨è¯¥ç¯å¢ƒã€‚
   

# æ•°æ®

## æ¦‚è¦

ç›®å‰ï¼ŒAladdinEduå¹³å°ä¸­çš„æ‰€æœ‰å­˜å‚¨å‡ä¸ºç½‘ç»œç›˜å½¢å¼çš„æ–‡ä»¶å­˜å‚¨ï¼Œå„å¥—é¤æƒç›Šæ‰€å«å­˜å‚¨å…è´¹é¢åº¦ä¸å¯æ‰©å±•ä¸Šé™è§ä¸‹è¡¨ï¼š

| å¥—é¤ç±»å‹       | ä½“éªŒç‰ˆ      | å°é²œç‰ˆ   | åˆçº§ç‰ˆ   | é«˜çº§ç‰ˆ   |
|:----------------:|:---------:|:----------:|:----------:|:----------:|
| å…è´¹æ–‡ä»¶å­˜å‚¨ç©ºé—´ | 30G     | 30G      | 60G      | 100G     |
| æœ€å¤§å¯æ‰©å±•ç©ºé—´  | ä¸å¯æ‰©å±•    | 500G     | 500G     | 2TB      |

>å­˜å‚¨è®¡è´¹è¯¦è§[æ–‡ä»¶å­˜å‚¨è®¡è´¹](#æ–‡ä»¶å­˜å‚¨è®¡è´¹)ï¼Œå¦‚éœ€æ›´å¤§çš„å®¹é‡è¯·æ‰«ç è”ç³»å®¢æœã€‚

## å­˜å‚¨ä½¿ç”¨Tips

### æ•°æ®ä¿ç•™è§„åˆ™

è‡ªå½“å‰ç®—åŠ›å¥—é¤å¤±æ•ˆã€è´¦å·ä¸äº«å¥—é¤æƒç›Šèµ·ï¼Œè‹¥15æ—¥å†…æœªç™»å½•è¿‡AladdinEduå¹³å°ï¼Œå­˜å‚¨èµ„æºå°†ä¼šè‡ªåŠ¨å›æ”¶ã€‚

## ä¸Šä¼ ä¸‹è½½æ•°æ®
>æ–‡ä»¶ä¼ è¾“çš„å¹³å‡é€Ÿåº¦ä¸º2-3M/sï¼Œå³°å€¼çº¦ä¸º5M/sã€‚å¦‚ä¼ è¾“é€Ÿåº¦ç¼“æ…¢ï¼Œå¯èƒ½æ˜¯ç”±äºå¸¦å®½è´Ÿè½½è¾ƒå¤§ï¼Œè¯·ç¨åå†è¯•ã€‚

### å°æ–‡ä»¶ä¼ è¾“ï¼ˆMçº§åˆ«æ–‡ä»¶ï¼‰

é€‰æ‹©å·¥ä½œç›®å½•åï¼Œå¯é€šè¿‡ç›´æ¥æ‹–æ‹½è‡³å·¥ä½œåŒºæ¥å¯¼å…¥æ–‡ä»¶ã€‚

   ![upload_folder](./pic/upload_folder.png)

### å¤§æ–‡ä»¶ä¼ è¾“ï¼ˆGçº§åˆ«æ–‡ä»¶ï¼Œå¼ºçƒˆæ¨èï¼‰

>ä¼ è¾“æ–‡ä»¶æ—¶ï¼Œæ¨èè°ƒæ•´workshopçš„èµ„æºè‡³å¯ç”¨èŒƒå›´å†…æœ€å¤§é…é¢ï¼Œä¿è¯ä¼ è¾“è¿‡ç¨‹ç¨³å®šã€‚

1. workshopåˆ›å»ºæˆåŠŸåï¼ŒæŸ¥çœ‹sshçš„é…ç½®æ–‡ä»¶ï¼š

- æŒ‰`Ctrl+Shift+P`å¿«æ·é”®ï¼Œé€‰æ‹©â€œRemote-SSH: Open SSH Configuration Fileâ€

   ![store1](./pic/store1.png)
   ![store2](./pic/store2.png)

- åœ¨é…ç½®æ–‡ä»¶ä¸­æ‰¾åˆ°workshopåç§°å¯¹åº”çš„Hostï¼Œå…¶ä¸­IdentityFileä¸ºå¯†é’¥æ–‡ä»¶ç›®å½•

   ![store3](./pic/store3.png)

2. é…ç½®sftpè½¯ä»¶ï¼Œä»¥FlieZilla Client ä¸ºä¾‹
<span style="color: red; font-weight: bold">è¿æ¥ã€ä¼ è¾“æ—¶éœ€ç¡®ä¿ workshop å¤„äº running çŠ¶æ€</span>

   ![store4](./pic/store4.png)

3. å‘/rootç›®å½•ä¸‹ä¼ è¾“æ–‡ä»¶

   ![store5](./pic/store5.png)

### scpæ–¹å¼ï¼ˆæ¨èMacç”¨æˆ·åŠLinuxç”¨æˆ·ä½¿ç”¨ï¼‰

```bash
#ä¸Šä¼ å‘½ä»¤
scp -r /æœ¬åœ°/ç›®å½• ${workshop name}:/root/è·¯å¾„

#ä¸‹è½½å‘½ä»¤
scp -r ${workshop name}:/root/è·¯å¾„ /æœ¬åœ°/è·¯å¾„
```

### å…¬ç½‘ç½‘ç›˜ä¼ è¾“

æ­£åœ¨æ–½å·¥ä¸­ï¼Œæ•¬è¯·æœŸå¾…~

# GPUè°ƒç”¨

## æ¦‚è¦

>å¯¹pythonæ–‡ä»¶æ”¯æŒGPU Debugã€GPU Runã€Run Taskï¼›å¯¹shellæ–‡ä»¶æ”¯æŒRun Shellã€Run Taskã€‚
ä»¥ä¸Šä»»åŠ¡è¿è¡Œå‡ä¸workshopçŠ¶æ€æ— å…³ï¼Œæ‚¨å¯åœ¨ä»»åŠ¡è¿è¡Œæ—¶åœæ­¢workshopã€‚

é™¤äº†Run Taskä¸ºè®­ç»ƒæ€ï¼Œå…¶ä»–åŠŸèƒ½å‡ä¸ºå¼€å‘æ€ï¼Œå³ä¼šæœ‰Logè¾“å‡ºï¼Œä½†æ˜¯ä¸ä¼šä¿å­˜ã€‚

### é…ç½®é¡µå‚æ•°ä»‹ç»

**åœ¨ä»£ç åŒºæˆ–å¯¹å¯¹åº”æ–‡ä»¶å³å‡»**ï¼Œç‚¹å‡»ç›¸åº”åŠŸèƒ½åå¼¹å‡ºå¦‚ä¸‹é…ç½®é¡µé¢ï¼š
   ![gpu1](./pic/gpu1.png)

| å‚æ•°åç§°                  | è¯´æ˜                                                                 | å¤‡æ³¨                                                                 |
|---------------------------|----------------------------------------------------------------------|----------------------------------------------------------------------|
| Configurations        | æŸ¥çœ‹å·²ä¿å­˜çš„é…ç½®ä¿¡æ¯                                                 | å¯å¿«é€Ÿè½½å…¥å†å²é…ç½®                                                   |
| Environment          | GPUè¿è¡Œçš„åŸºç¡€é•œåƒ                                                   |å¼ºçƒˆæ¨èä¸workshopçš„é•œåƒä¿æŒä¸€è‡´ |
| Resource              | GPUè°ƒç”¨æ—¶åˆ†é…åˆ°çš„èµ„æº                                                 | - å¯é€‰æ‹©æ˜¾å¡æ•°é‡ã€å‹å·<br>- å¡å‹å·åå†…å®¹ä¸ºç³»ç»Ÿè‡ªåŠ¨é€‚é…çš„CPUã€å†…å­˜<br><span style="color: red">â€» 40Gå¡å‹æš‚ä¸æ”¯æŒä½¿ç”¨å¤šå¡</span> |
| Save as configuration | ä¿å­˜å½“å‰GPUè°ƒç”¨é…ç½®                                                 | å‹¾é€‰åå¯ä¾›ä¸‹æ¬¡ç›´æ¥è°ƒç”¨                                               |
| ENV                   | ç¯å¢ƒå˜é‡é…ç½®                                                       | æ”¯æŒé”®å€¼å¯¹å½¢å¼æ³¨å…¥                                                   |
| Args                  | å‘½ä»¤è¡Œå‚æ•°                                                         | æŒ‰éœ€ä¼ å…¥æ‰§è¡Œå‚æ•°                                                     |
| Python Module         | Pythonæ¨¡å—å…¥å£                                                     | æ”¯æŒPythonæ¨¡å—                                       |
| Work Dir              | å·¥ä½œç›®å½•è·¯å¾„                                                       | ä¸åŒé¡¹ç›®å¯é…ç½®ä¸åŒè·¯å¾„                                               |

> "6C 80G"æ˜¯æŒ‡ä¸ºæ¯å¡åˆ†é…äº†6ä¸ªCPUä¸80Gå†…å­˜ï¼Œä»¥æ­¤ç±»æ¨ã€‚**æ¯å¹¶è¡Œåº¦å¯ç”¨CPUæ•°ä¸º10ï¼Œå†…å­˜ä¸º121Gï¼Œè¶…å‡ºåå°†æŠ¥é”™è¶…å‡ºquota**ï¼›

### å¸¸ç”¨åŠŸèƒ½ä»‹ç»

æäº¤è°ƒç”¨GPUï¼ˆæ‰€æœ‰ç±»å‹ï¼‰æˆåŠŸåï¼Œå¯¹**RunningçŠ¶æ€**ä¸‹çš„è¿›ç¨‹ï¼Œå¯ä»¥é€šè¿‡å³å‡» DEVELOP SESSION ä¸­çš„å¯¹åº”sessionï¼Œè¿›è¡Œä¸‹åˆ—æ“ä½œï¼š

   ![gputask](./pic/gputask.png)

| æ“ä½œ       | åŠŸèƒ½æè¿°                     | ä½¿ç”¨åœºæ™¯               |
|:----------:|:---------------------------:|:---------------------:|
| Terminal   | æ‰“å¼€è¿è¡Œç»ˆç«¯ï¼Œå®æ—¶æŸ¥çœ‹è¿›ç¨‹çŠ¶æ€å’ŒGPUä½¿ç”¨ç‡ | ä½¿ç”¨nvidia-smiæˆ–nvi-topå®æ—¶ç›‘æ§GPUçŠ¶æ€      |
| View Log   | æŸ¥çœ‹ä»»åŠ¡å®æ—¶/å†å²è¿è¡Œæ—¥å¿—      | æ£€æŸ¥æ‰§è¡Œç»“æœå’Œé”™è¯¯     |
| Copy Path  | å¤åˆ¶logç›®å½•è·¯å¾„ï¼ˆRun TaskåŠŸèƒ½ä¸“å±ï¼‰ | åœ¨ç»ˆç«¯å¿«é€Ÿè®¿é—®æ—¥å¿—ç›®å½• |
| Delete     | æ‰‹åŠ¨ç»ˆæ­¢è¿›ç¨‹å¹¶é‡Šæ”¾èµ„æº        | åœæ­¢å¼‚å¸¸ä»»åŠ¡          |

## GPU Debug

æä¾› Debug è°ƒè¯•åŠŸèƒ½ï¼Œæ”¯æŒæ–­ç‚¹è°ƒè¯•ï¼Œå¹¶åœ¨è°ƒè¯•æ§åˆ¶å°ä¸­æŸ¥çœ‹è¾“å‡ºä¿¡æ¯ã€‚

![debug1](./pic/debug1.png)

## GPU Run

GPU Runæä¾›ä¸VSCodeç›´æ¥Runä»£ç ç±»ä¼¼çš„å¼€å‘æ€æ‰§è¡Œä½“éªŒï¼Œè¿è¡ŒLogé»˜è®¤ä¼šåœ¨è¾“å‡ºä¸­å±•ç¤ºã€‚è¿è¡Œç»“æŸåå°†ä¼šè‡ªåŠ¨é‡Šæ”¾èµ„æºï¼Œåœæ­¢è®¡è´¹ã€‚

## Run Shell

ä¸GPU Runç±»ä¼¼ï¼ŒRun Shellå¯ç”¨äºè¿è¡Œshè„šæœ¬ï¼Œä¹Ÿå¯ç”¨äºç¼–è¯‘ç¯å¢ƒï¼Œä½†å¦‚ä¸Šæ–‡æ‰€è¯´ç¼–è¯‘åçš„ç¯å¢ƒåªä¼šä¿å­˜åœ¨ä¸´æ—¶å­˜å‚¨ä¸­ï¼Œå…³é—­workshopåä¼šæ¸…é™¤ã€‚
>æ³¨ï¼šshæ–‡ä»¶ä¸­éœ€è¦æ·»åŠ conda activate [ä½ çš„ç¯å¢ƒå]å‘½ä»¤ï¼Œæˆ–åœ¨.bashrcæ–‡ä»¶ä¸­ç›´æ¥æ¿€æ´»condaç¯å¢ƒã€‚

## Run Task

Run Taskä½œä¸ºå”¯ä¸€è®­ç»ƒæ€åŠŸèƒ½ï¼Œå¯ç”¨äºè¿è¡Œå¤šworkeråˆ†å¸ƒå¼ä»»åŠ¡ï¼ˆtorchrunï¼‰ã€‚æ­¤æ—¶GPUå¹¶è¡Œåº¦=GPUæ•°*workeræ•°ã€‚

   ![task1](./pic/task1.png)

è¿è¡ŒTaskæ—¶é»˜è®¤ä¸ä¼šæœ‰Logè¾“å‡ºã€‚å¦‚éœ€æŸ¥çœ‹æ—¥å¿—ï¼Œéœ€åœ¨sessionä¸­ç­‰å¾…TaskçŠ¶æ€åˆ‡æ¢ä¸ºRunningåï¼Œå³å‡»â€œView logâ€æŸ¥çœ‹ï¼›æˆ–å³å‡»â€œcopy pathâ€ï¼Œå¤åˆ¶æ—¥å¿—æ–‡ä»¶ç›®å½•åˆ°ç»ˆç«¯ä¸­ï¼Œé€šè¿‡cdæ‰“å¼€æŸ¥çœ‹ã€‚

åŒæ—¶ï¼ŒRun Taskæ”¯æŒåœ¨æœ¬åœ°VSCodeä¸­æŸ¥çœ‹æˆ–ä¸‹è½½æ—¥å¿—ã€‚

   ![GPUtask](./pic/gputask3.png) 
   ![GPUtask](./pic/gputask2.png)

- æ“ä½œä»‹ç»

| æ“ä½œ     | åŠŸèƒ½æè¿°                     |
|:--------:|:---------------------------:|
| View Log   | æŸ¥çœ‹Taskçš„æ—¥å¿—ä¿¡æ¯           |
| Log Download  | ä¸‹è½½Taskçš„æ—¥å¿—ä¿¡æ¯åˆ°æœ¬åœ°           |
| Stop     | åœæ­¢å½“å‰æ­£åœ¨è¿è¡Œçš„Task       |
| Monitor  | èµ„æºç›‘è§†å™¨ï¼Œå¯æŸ¥çœ‹CPUã€å†…å­˜ã€GPUä½¿ç”¨æƒ…å†µ |
| Delete   | åˆ é™¤Taskçš„æ—¥å¿—ä¿¡æ¯           |

>æœ¬åœ°VSCodeä¸­ï¼ŒDeleteåŠŸèƒ½ä¼šåœæ­¢Taskå¹¶åˆ é™¤æ—¥å¿—ä¿¡æ¯ã€‚

## å‘½ä»¤è¡Œæ‰§è¡ŒGPUè°ƒç”¨

â— **é‡è¦** â—ï¼š

1ï¸âƒ£ ä½¿ç”¨å‘½ä»¤è¡Œè¿æ¥workshopå‰ï¼Œéœ€è¦è‡³å°‘**æ‰“å¼€**ä¸€æ¬¡å¯¹åº”çš„workshopã€‚

2ï¸âƒ£ ä½¿ç”¨æœŸé—´éœ€è¦ä¿æŒ**æœ¬åœ°**VSCodeå¤„äºæ‰“å¼€çŠ¶æ€ï¼Œä¸èƒ½å…³é—­ã€‚

3ï¸âƒ£ æš‚æ—¶æ— æ³•ä½¿ç”¨å‘½ä»¤è¡ŒæŸ¥çœ‹æ—¥å¿—ï¼Œé¢„è®¡åœ¨ä¸‹ç‰ˆæœ¬ä¸­å¢åŠ ã€‚

1. Openéœ€è¦é€šè¿‡å‘½ä»¤è¡Œè¿æ¥çš„workshopï¼Œç„¶ååœ¨æœ¬åœ°VSCodeç»ˆç«¯ä¸­ä½¿ç”¨sshè¿æ¥ï¼Œæ³¨æ„è¿œç¨‹æœåŠ¡å™¨åœ°å€æ˜¯ [å³å°†è¿æ¥çš„workshopåç§°]+.bj1ï¼š

   ![tcl1](./pic/tcl1.png) 

2. åœ¨ç»ˆç«¯ä¸­è¾“å…¥aladdin -hï¼ŒæŸ¥çœ‹å¯ç”¨å‘½ä»¤åŠå…¶ç›¸å…³ç”¨æ³•ï¼š

   ![tcl2](./pic/tcl2.png) 

3. åŒæ ·åœ°ï¼Œä¹Ÿå¯ä»¥ç”¨ç›¸åŒæ–¹æ³•æŸ¥çœ‹ä»¥ä¸Šå„å‘½ä»¤çš„ä½¿ç”¨æ–¹æ³•å’Œç›¸å…³å‚æ•°ï¼š
   >æ³¨ï¼šè‹¥ä»…ä½¿ç”¨CPUè¿è¡Œä»»åŠ¡ï¼Œéœ€è¦å¯¹ --cpu int å’Œ --mem int ä¸¤ä¸ªå‚æ•°è¿›è¡Œèµ‹å€¼ä¿®æ”¹ã€‚è‹¥ä½¿ç”¨GPUè¿è¡Œä»»åŠ¡ï¼Œåˆ™è¿™ä¸¤ä¸ªå‚æ•°æ˜¯å›ºå®šå€¼ï¼Œæ— æ³•ä¿®æ”¹ã€‚

   ![tcl3](./pic/tcl3.png) 

4. ä»¥å¿«é€Ÿå¼€å§‹ä¸­çš„Demoä¸ºä¾‹ï¼Œä½¿ç”¨80G GPUå¡çš„è¿è¡Œå‘½ä»¤ä¸ºï¼š

   ```bash
   aladdin run -f gputest.py --gpu-type nvidia.com/gpu-h100-80gb-hbm3 --gpu-count 1 --image registry.hd-01.alayanew.com:8443/aladdin/torch:2.6.0-cu124
   ```

   è¾“å‡ºç¤ºä¾‹å¦‚ä¸‹ï¼Œå…¶ä¸­å¯ä»¥çœ‹åˆ°å¯åŠ¨GPUä»»åŠ¡æ—¶çš„å‚æ•°ä¿¡æ¯ï¼Œå¹¶ä¸”è‡ªåŠ¨ä¿®æ­£äº†CPUå’Œå†…å­˜çš„å¤§å°ï¼š
   ```bash
   2025/06/20 09:57:12 [WARNING] Fix Cpu to 13, Mem to 200, because gpu-type is nvidia.com/gpu-h100-80gb-hbm3, gpu-count is 1
   2025/06/20 09:57:12 
   File            : gputest.py
   Image           : registry.hd-01.alayanew.com:8443/aladdin/torch:2.6.0-cu124
   Resource        : Cpu: 13(H), Mem: 200(GB), Gpu: nvidia.com/gpu-h100-80gb-hbm3(1)
   PythonEnv       : /usr/bin/python
   DeleteSession   : false
   SaveAsConfig    :
   Env             :
   Args            :
   WorkDir         : /root
   Ports           : []

   2025/06/20 09:45:24 start success. name: run-6056d7a71bd549a0b2, id: d828bfc2-1b57-4d28-b64f-f0bbb0be0df6
   ```

5. æ—¥å¿—æŸ¥çœ‹å‘½ä»¤æ­£åœ¨å¼€å‘ä¸­ï¼Œç›®å‰ä»…å¯é€šè¿‡Sessionçš„View LogåŠŸèƒ½æŸ¥çœ‹ï¼š

   ![tcl4](./pic/tcl4.png) 

## ç«¯å£è½¬å‘

â— **é‡è¦** â—ï¼š


1ï¸âƒ£ å¦‚æœè¿œç«¯æœåŠ¡ä½¿ç”¨ç»“æŸï¼Œä¸€å®šè¦è®°å¾—**æ‰‹åŠ¨delete** shellä»»åŠ¡ï¼Œå¦åˆ™ä¼šä¸€ç›´å ç”¨GPUèµ„æºï¼Œäº§ç”Ÿä¸å¿…è¦çš„è´¹ç”¨ã€‚

2ï¸âƒ£ æ‰€æœ‰server**å¿…é¡»ç»‘å®š0.0.0.0**ï¼Œä¸èƒ½ä½¿ç”¨127.0.0.1æˆ–localhostã€‚

3ï¸âƒ£ æš‚ä¸æ”¯æŒTCPåè®®ï¼Œä»…æ”¯æŒHTTPåè®®ã€‚

### ä½¿ç”¨ç«¯å£è½¬å‘å¯åŠ¨Jupyter

1. å¯åŠ¨workshopï¼Œè¿›å…¥è¿œç«¯é¡µé¢åï¼Œé€‰æ‹©/rootç›®å½•ä½œä¸ºå·¥ä½œè·¯å¾„ã€‚

   ![OpenFolder](./pic/OpenFolder.png) 

2. æ‰“å¼€è¿œç«¯é¡µé¢ç»ˆç«¯ï¼Œè¾“å…¥ä»¥ä¸‹å‘½ä»¤å®‰è£…Jupyterï¼š
``` bash
# ç”¨ Anaconda å®‰è£…
conda install jupyter notebook
# ç”¨ pip å®‰è£…
pip install jupyter notebook
```

- é€šè¿‡ä»¥ä¸‹ä»£ç éªŒè¯Jupyteræ˜¯å¦å®‰è£…æˆåŠŸï¼š
``` bash
jupyter --version
```

  - è¾“å‡ºç¤ºä¾‹å¦‚ä¸‹ï¼š

``` text
Selected Jupyter core packages...
IPython          : 8.36.0
ipykernel        : 6.29.5
ipywidgets       : 8.1.7
jupyter_client   : 8.6.3
jupyter_core     : 5.7.2
jupyter_server   : 2.16.0
jupyterlab       : 4.4.2
nbclient         : 0.10.2
nbconvert        : 7.16.6
nbformat         : 5.10.4
notebook         : 7.4.2
qtconsole        : not installed
traitlets        : 5.14.3
```

3. åœ¨/rootç›®å½•ä¸‹æ–°å»º.shæ–‡ä»¶ï¼Œè¾“å…¥ä»¥ä¸‹å‘½ä»¤ï¼š

``` bash
#æ¿€æ´»åŒ…å«jupyterçš„ç¯å¢ƒ
conda activate [ä½ çš„ç¯å¢ƒ]

jupyter notebook --allow-root --listen 0.0.0.0
```
4. åœ¨ä»£ç åŒºæˆ–å¯¹.shæ–‡ä»¶å³å‡»ï¼Œé€‰æ‹©Run Shellè¿è¡Œï¼Œé€šè¿‡ä»»ä¸€æ–¹æ³•æ·»åŠ ç«¯å£ï¼š
 - **æ–¹æ³•1**ï¼šé€šè¿‡Run Shellé…ç½®é¡µ<sup>1</sup>æ·»åŠ ç«¯å£
 å±•å¼€â€œAdvancedâ€åï¼Œç‚¹å‡»â€œ+Add External Accessâ€<sup>2</sup>æ–°å»ºç«¯å£ï¼Œè¾“å…¥ç«¯å£å·<sup>3</sup>ï¼ˆJupyter Severå¯åŠ¨ç«¯å£å·é»˜è®¤ä¸ºâ€œ8888â€ï¼‰ï¼Œæäº¤è¿è¡Œ

    ![runshell](./pic/runshell.png) 

 - **æ–¹æ³•äºŒ**ï¼šRun Shellå¯åŠ¨åï¼Œå³å‡»**Running**çš„sessionï¼Œé€‰æ‹©â€œAdd External Accessâ€ï¼Œåœ¨å¼¹å‡ºçª—å£ä¸­è¾“å…¥ç«¯å£å·

    ![addport](./pic/addport.png)

>æ³¨æ„ï¼š.shæ–‡ä»¶åªæœ‰å¤„äºRunningä¸­æ‰èƒ½æ–°å»ºç«¯å£ï¼Œsuccessæˆ–failedçŠ¶æ€ä¸‹ï¼Œéƒ½ä¸å¯æ–°å»ºç«¯å£ã€‚

### è®¿é—®ç«¯å£
1. Run Shellè¾“å‡ºä¸­æ‰“å°äº†sever urlåï¼Œç‚¹å‡»sessionä¸‹çš„ç«¯å£åç§°å³ä¾§çš„ç®­å¤´ï¼Œæ­¤æ—¶æµè§ˆå™¨ä¸­å¼¹å‡ºJupyterç½‘é¡µï¼š

   ![portmapping](./pic/portmapping.png)
   ![JupyterBrowser](./pic/JupyterBrowser.png)

2. åœ¨è¾“å‡ºä¸­æ‰¾åˆ°tokenï¼Œåœ¨Juypterç½‘é¡µä¸­å¡«å†™ï¼Œç™»å½•JupyteræœåŠ¡å™¨ï¼š

   ![token](./pic/token.png)
3. å¯åŠ¨JupyteræœåŠ¡å™¨åï¼Œå¯å€ŸåŠ©Jupyterå®ç°å¦‚ä¸‹åŠŸèƒ½ï¼š

- **åŠŸèƒ½1**ï¼šåœ¨æµè§ˆå™¨ä¸­ä½¿ç”¨Jupyter
  é€šè¿‡Jupyterç½‘é¡µï¼Œå¯ä»¥çœ‹åˆ°/rootç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶ï¼Œå¹¶åœ¨Jupyterä¸­ç¼–è¯‘ä»£ç 

     ![jupyter1](./pic/jupyter1.png)

- **åŠŸèƒ½2**ï¼šåœ¨VSCodeä¸­ä½¿ç”¨Jupyterï¼ˆ**éœ€æå‰å®‰è£…Jupyterå’ŒPythonæ’ä»¶**ï¼‰
  ï¼ˆ1ï¼‰åœ¨workshopä¸­æ–°å»º.ipynbæ–‡ä»¶ï¼ˆJupyteræ–‡ä»¶ï¼‰

    ![jupyterNotebook](./pic/jupyterNotebook.png)

    ï¼ˆ2ï¼‰é€‰æ‹©Select Kernel -> Existing Jupyter Server

    ![selectkernel](./pic/selectkernel.png)
    ![existing](./pic/existing.png)

    è¾“å…¥Jupyteræµè§ˆå™¨åœ°å€ï¼Œå›è½¦

    ![jupyterurl](./pic/jupyterurl.png)
    ![jupyterurl1](./pic/jupyterurl1.png)

    è¾“å…¥tokenï¼Œå›è½¦

    ![confirm](./pic/confirm.png)

    ç»§ç»­å›è½¦

    ![confirm1](./pic/confirm1.png)

    é€‰æ‹©Python 3

    ![python3](./pic/python3.png)

    æ–‡ä»¶å³ä¸Šè§’å˜æˆäº†Python 3(ipykernel)ï¼Œè¯´æ˜è®¾ç½®æˆåŠŸï¼Œæ­¤æ—¶å°±å¯åœ¨VSCodeä¸­åˆ©ç”¨Jupyterçš„åŠŸèƒ½è°ƒè¯•ä»£ç äº†ã€‚

    ![setting](./pic/setting.png)

    ï¼ˆ3ï¼‰éªŒè¯æ˜¯å¦å¯ç”¨ï¼šåœ¨Jupyterç½‘é¡µä¸­æ–°å»ºä»»æ„æ–‡ä»¶ï¼Œç„¶ååœ¨VSCodeè¾“å…¥ä»¥ä¸‹ä»£ç ï¼Œè¿è¡Œæµ‹è¯•ã€‚
    ``` bash
    import torch
    torch.cuda.is_available()
    ```
    å¦‚æœcondaç¯å¢ƒä¸­å«æœ‰torchï¼Œåˆ™æœ‰ç±»ä¼¼ä¸‹æ–‡çš„è¾“å‡ºï¼š
    ``` text
    True
    ```
    ![torch_output](./pic/torch_output.png)

### ä¸‹è½½ä½¿ç”¨ComfyUI
1. åœ¨è¿œç«¯é¡µé¢ç»ˆç«¯ä¸­æ‰§è¡Œä»¥ä¸‹å‘½ä»¤ï¼Œcloneä»£ç ï¼š
``` bash
git clone https://gh-proxy.com/github.com/comfyanonymous/ComfyUI.git
```
   ![clonecomfyUI](./pic/clonecomfyUI.png)

2. ä¸‹è½½å®Œæˆåï¼Œåœ¨ComfyUIæ–‡ä»¶å¤¹ä¸‹æ–°å»ºrun.shæ–‡ä»¶ï¼Œå°†ä»¥ä¸‹ä»£ç å¤åˆ¶åˆ°run.shæ–‡ä»¶ä¸­ï¼š
``` bash
apt update && apt install -y cmake g++ make
pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu128
pip install -r requirements.txt -i https://mirrors.tuna.tsinghua.edu.cn/pypi/web/simple
python main.py --listen 0.0.0.0 --port 8188
```
3. åœ¨ä»£ç åŒºæˆ–å¯¹æ–‡ä»¶å³å‡»ï¼Œé€‰æ‹©Run Shellè¿è¡Œï¼Œå¡«å†™é…ç½®æ—¶éœ€æ³¨æ„ï¼š
- è‹¥æ‰“å¼€æ–‡ä»¶ç›®å½•ä¸º/rootï¼Œåˆ™éœ€åœ¨é«˜çº§é…ç½®çš„â€œWork Dirâ€ä¸­å¡«å†™æ–‡ä»¶è·¯å¾„ï¼Œå³â€œComfyUIâ€ 
- æ·»åŠ å¤–éƒ¨è®¿é—®ç«¯å£ï¼Œæ­¤å¤„é¡»ä¸portå‚æ•°ä¿æŒä¸€è‡´ï¼Œå³å¡«å†™â€œ8188â€

   ![workdir](./pic/workdir.png)

4. ç‚¹å‡»Submitåæäº¤ä»»åŠ¡ï¼Œç­‰å¾…å®‰è£…å¹¶è¿è¡Œ

5. å®‰è£…å®Œæˆåï¼Œç‚¹å‡»sessionä¸‹çš„ç«¯å£åç§°å³ä¾§çš„ç®­å¤´ï¼Œå³å¯æ‰“å¼€ç½‘é¡µï¼Œé€šè¿‡æµè§ˆå™¨è®¿é—®æœåŠ¡ã€‚

   ![comfyUI](./pic/comfyUI.png)


# å¸¸è§é—®é¢˜

## workshopç›¸å…³é—®é¢˜

**Qï¼šå¯åŠ¨workshopæ—¶Environmentæ æ— å†…å®¹ï¼Œå¦‚ä½•å¤„ç†ï¼Ÿ**

âœ… ç½‘ç»œå»¶è¿Ÿæˆ–è®¾å¤‡å¡é¡¿å¼•èµ·ï¼Œç¨ç­‰ç‰‡åˆ»å³å¯ã€‚

**Qï¼šå¯åŠ¨workshopåæç¤ºå¡«å†™localhostå¯†ç ï¼Œå¦‚ä½•å¤„ç†ï¼Ÿ**

âœ… è¿™ç§æƒ…å†µä¸‹æ˜¯ç”±äºæ‚¨å½“å‰è®¾å¤‡ä¸­å¯è®¿é—® ~/.ssh æˆ– ~/.alaya/ssh çš„ç”¨æˆ·è¿‡å¤šï¼Œåˆ é™¤è‡³ä»…å½“å‰ç™»å½•ç”¨æˆ·å¯è®¿é—®å³å¯æ¢å¤æ­£å¸¸ï¼Œç‚¹å‡»æŸ¥çœ‹[è§£å†³æ–¹æ¡ˆé“¾æ¥](https://blog.csdn.net/chaoenhu/article/details/103698804)ã€‚

**Qï¼šworkshopæ‰“å¼€è¿œç«¯é¡µé¢å¤±è´¥ï¼Œæç¤ºâ€œæ— æ³•ä¸ â€˜åˆ›å»ºçš„workshopâ€™ å»ºç«‹è¿æ¥â€ã€‚**

âœ… éœ€è¦æ£€æŸ¥æœ¬åœ°æ˜¯å¦å¯åŠ¨äº†å…¨å±€ä»£ç†æ¨¡å¼çš„ç§‘å­¦ä¸Šç½‘ã€‚å¦‚æœ‰ï¼Œå¯å°è¯•å…³é—­åå†é‡å¯ã€‚ä¹Ÿå¯åœ¨æœ¬åœ°ç»ˆç«¯ä¸­ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤æ£€æŸ¥sshè¿æ¥æ˜¯å¦æ­£å¸¸ã€‚

``` bash
ssh -vv [å‡ºç°çš„é—®é¢˜çš„workshopåç§°].bj1
```

**Qï¼šè¿œç«¯é¡µé¢ä¸­æœªæ˜¾ç¤ºAladdinæ’ä»¶å›¾æ ‡ï¼Œå¦‚ä½•å¤„ç†ï¼Ÿ**

âœ… åœ¨è¿œç«¯é¡µé¢ä¸­å¸è½½Aladdinæ’ä»¶ï¼Œç„¶ååœ¨æœ¬åœ°çš„VSCodeä¸­å³å‡»æœ‰é—®é¢˜çš„workshopï¼Œç‚¹å‡»"Install Remote"æ‰‹åŠ¨å®‰è£…ã€‚

**Qï¼šåœ¨workshopä¸­è£…äº†gccï¼Œä¸ºä»€ä¹ˆGPU Runæ—¶å´æ— æ³•ä½¿ç”¨ï¼Ÿ**

âœ… ä»»ä½•æ²¡æœ‰è£…åœ¨/rootç›®å½•ä¸‹çš„æ–‡ä»¶éƒ½ä¸ä¼šè¢«ä¿å­˜ï¼Œç±»ä¼¼æƒ…å†µå¯é€šè¿‡ä¿å­˜é•œåƒè§£å†³ã€‚

**Qï¼šworkshopä¸­æŠ¥é”™â€œæ— æ³•æ¿€æ´» â€˜Aladdinâ€™ æ‰©å±•, å› ä¸ºå®ƒä¾èµ–äºæœªåŠ è½½çš„ â€˜Remote - SSH: Editing Configuration Filesâ€™ æ‰©å±•ã€‚æ˜¯å¦è¦é‡æ–°åŠ è½½çª—å£ä»¥åŠ è½½æ‰©å±•åï¼Ÿâ€**

âœ… å°†è¿œç«¯é¡µé¢ä¸­çš„Aladdinæ’ä»¶å¸è½½å³å¯ï¼Œæ³¨æ„éœ€**ä¿ç•™Aladdin Remote**æ’ä»¶ã€‚æˆ–é€šè¿‡åœ¨è¿œç«¯é¡µé¢ç»ˆç«¯ä¸­æ‰§è¡Œå‘½ä»¤å¸è½½ï¼Œå‘½ä»¤å¦‚ä¸‹ï¼š
``` bash
#VSCodeç‰ˆæœ¬
code --uninstall-extension AlayaNeW.aladdin

#Cursorç‰ˆæœ¬
cursor --uninstall-extension AlayaNeW.aladdin

```

ğŸˆå¦‚æ‚¨çš„é—®é¢˜ä»æ— æ³•è§£å†³ï¼Œå¯å…³æ³¨å¾®ä¿¡æœåŠ¡å·â€œä¹ç« äº‘æAladdinEduâ€ï¼Œç‚¹å‡»èœå•æ ä¸­çš„â€œé™æ—¶æ´»åŠ¨â€ > â€œå…¨æ°‘æ‰¾bugâ€ï¼Œæ ¹æ®é—®å·æç¤ºå¡«å†™ç›¸åº”æŠ¥é”™ä¿¡æ¯ï¼Œç­‰å¾…å·¥ä½œäººå‘˜è”ç³»ã€‚

## GPUè°ƒç”¨ç›¸å…³é—®é¢˜ 

Qï¼šè°ƒç”¨GPUæ—¶å‡ºç°å¦‚ä¸‹æŠ¥é”™ï¼Œè¯¥å¦‚ä½•å¤„ç†ï¼Ÿ 
```
pods "run-xxxxx" is forbidden: exceeded quota: vks-xxx, requested: limits.cpu=26,limits.memory=400Gi,requests.cpu=26,requests.memory=400Gi, used: limits.cpu=2,limits.memory=8Gi,requests.cpu=2,requests.memory=8Gi, limited: limits.cpu=20,limits.memory=224Gi,requests.cpu=20,requests.memory=224Gi
```

âœ… è¿™æ˜¯ç”±äºworkshopå ç”¨çš„CPUèµ„æºè¿‡å¤šï¼Œå¯¼è‡´å¯åŠ¨æ—¶GPUä»»åŠ¡èµ„æºä¸è¶³ã€‚

  è§£å†³æ–¹æ³•ï¼š
  
  - æ£€æŸ¥æ˜¯å¦æœ‰å¤šä¸ªæ­£åœ¨è¿è¡Œçš„workshopã€‚å¦‚æœ‰ï¼Œå°†å…¶ä»–workshopå…³é—­ã€‚
  
  - å°†å½“å‰workshopçš„èµ„æºè°ƒæ•´ä¸º2æ ¸4Gï¼ˆå³å‡»å½“å‰workshop > Edit > **é‡å¯workshop**ï¼‰ï¼Œé‡å¯workshopåå³å¯æ­£å¸¸è¿è¡ŒGPUä»»åŠ¡ã€‚

Qï¼šæ•°æ®åŠ è½½é€Ÿåº¦å¾ˆæ…¢ï¼Œè¯¥å¦‚ä½•è§£å†³?

âœ… æ‚¨å¯æ ¹æ®æ•°æ®å¤§å°å°è¯•ä»¥ä¸‹ä¸¤ç§ä¼˜åŒ–æ–¹æ³•ã€‚

- æ–¹æ³•1ï¼šä½¿ç”¨å¤šè¿›ç¨‹ï¼Œä»ç£ç›˜ä¸­è¯»å–æ•°æ® --> éœ€åœ¨dataloaderé‡Œè®¾ç½®å¤šCPUå¹¶è¡Œï¼Œ
80Gå’Œ40Gå¡å¯åˆ†åˆ«ä½¿ç”¨10æ ¸å’Œ5æ ¸CPUå¸®åŠ©å¤„ç†æ•°æ®ï¼›

- æ–¹æ³•2ï¼šä»å†…å­˜ä¸­è¯»å–æ•°æ®ï¼Œé™æ•°æ®é›†å°äºç­‰äº30Gæ—¶ --> å°†æ•°æ®é›†copyåˆ°/dev/shmç›®å½•ä¸‹ï¼Œå³å¯ä½¿ç”¨å†…å­˜åŠ è½½æ•°æ®ã€‚

# å……å€¼ä¸è®¡è´¹

## å……å€¼

AladdinEduå¹³å°ç›®å‰é‡‡ç”¨è®¢é˜…åˆ¶ã€‚ç”¨æˆ·å¯è®¢é˜…ä¸åŒç±»å‹å¥—é¤ä»¥è´­ä¹°ç®—åŠ›ï¼Œå¥—é¤æƒç›Šè§ä¸‹è¡¨ï¼š
| å¥—é¤åç§°               |ä½“éªŒç‰ˆ| å°é²œç‰ˆ | åˆçº§ç‰ˆ | é«˜çº§ç‰ˆ | æ‰©å±•åŒ… |
|:---------------------:|:------:|:------:|:------:|:------:|:------:|
| å¥—é¤å†…ç®—åŠ›/DCU        | 5.12     | 20     | 270   | 2400    | 10     |
| GPUå¹¶è¡Œåº¦             | 1      | 2      | 4      | 8      | -      |
| å…è´¹å­˜å‚¨ç©ºé—´/G        | 30      |30     | 60     | 100    | -      |
| æœ€å¤§å¯æ‰©å±•å­˜å‚¨ç©ºé—´/G   | ä¸å¯æ‰©å±• |500     | 500     | 2000    | -      |
| éæ•™è‚²ç”¨æˆ·è´¹ç”¨/å…ƒ     |æ³¨å†Œå³é€| 198    | 2500    | 21000   | 99    |
| æ•™è‚²ç”¨æˆ·è´¹ç”¨/å…ƒ        | æ³¨å†Œå³é€| 158    | 2000    | 16800   | 79     |

> ï¼ˆ1ï¼‰DCUï¼Œå³åº¦ï¼ŒAladdinEduå¹³å°é‡‡ç”¨çš„ç®—åŠ›åŸºæœ¬è®¡é‡å•ä½ï¼Œ1 DCU =312 TFLOPS *1 hourã€‚
> ï¼ˆ2ï¼‰æ–°ç”¨æˆ·æ³¨å†Œå³äº«5.12DCUå…è´¹ä½“éªŒç®—åŠ›ã€‚

æ‚¨å¯åœ¨AladdinEduå¹³å°ç›´æ¥è®¢é˜…å¥—é¤ï¼Œç›®å‰ä»…æ”¯æŒé€šè¿‡æ”¯ä»˜å®åœ¨çº¿æ”¯ä»˜ã€‚**åŒæ—¶æ¨èæ‚¨æ·»åŠ å®¢æœä¼ä¸šå¾®ä¿¡ï¼Œè·å–æœ€æ–°æ´»åŠ¨ä¸ä¼˜æƒ æ”¿ç­–ã€‚**

## å‘ç¥¨

AladdinEduå¹³å°æ”¯æŒå¼€ç¥¨ï¼Œé¡¹ç›®åç§°ä¸ºâ€œæŠ€æœ¯æœåŠ¡è´¹â€ã€‚å¦‚æœ‰å¼€ç¥¨éœ€æ±‚ï¼Œå¯è”ç³»å®¢æœåŠç†ã€‚

## è®¡è´¹
### GPUè®¡è´¹
AladdinEduå¹³å°ç›®å‰æä¾›ä¸¤ç§GPUï¼Œè§„æ ¼å¦‚ä¸‹ï¼š
| è§„æ ¼å‚æ•°               | DC100ï¼ˆHopperï¼‰40G         | DC100ï¼ˆHopperï¼‰80G         |
|:-----------------------:|:---------------------------:|:---------------------------:|
| æ˜¾å­˜å¤§å°          | 40GB                      | 80GB                      |
| ç®—åŠ›å®šä»·          | 1.28 DCU/H                | 2.56 DCU/H                |
| å¹¶è¡Œåº¦å ç”¨        | 1                         | 2                         |

>æƒç›Šï¼š1 * DC100ï¼ˆHopperï¼‰40G + 2 * DC100ï¼ˆHopperï¼‰80G <= è®¢é˜…å¥—é¤çš„æœ€å¤§å¹¶è¡Œåº¦
### æ–‡ä»¶å­˜å‚¨è®¡è´¹

æŒ‰å®é™…ä½¿ç”¨é‡å¼¹æ€§è®¡è´¹ï¼Œæ¯ä¸ªå¥—é¤åŒ…å«çš„å…è´¹å­˜å‚¨é¢åº¦ä»¥å®˜ç½‘å±•ç¤ºä¸ºå‡†ã€‚

- è®¡è´¹è§„åˆ™ï¼š

ï¼ˆ1ï¼‰ç³»ç»Ÿå°†ä»¥å½“æ—¥ï¼ˆè‡ªç„¶æ—¥ï¼‰ä½¿ç”¨çš„æœ€å¤§å®¹é‡ä¸ºè®¡è´¹å®¹é‡ï¼Œè¶…å‡ºå…è´¹å®¹é‡çš„è´¹ç”¨ï¼ˆå…ƒ/æ—¥ï¼‰ = è¶…å‡ºå®¹é‡ï¼ˆGBï¼‰ Ã— 0.0015DCU/GB/æ—¥ï¼Œæ¬¡æ—¥å‡Œæ™¨æ‰£é™¤å½“æ—¥è´¹ç”¨ï¼›

ä¸¾ä¾‹ï¼šå°é²œç‰ˆå¥—é¤ç”¨æˆ·äº«æœ‰30Gå…è´¹å­˜å‚¨ç©ºé—´ï¼Œå¦‚æœå½“æ—¥ä½¿ç”¨çš„æœ€å¤§å®¹é‡ä¸º50GBï¼Œé‚£ä¹ˆå½“æ—¥äº§ç”Ÿçš„æ–‡ä»¶å­˜å‚¨è´¹ç”¨ = (50 - 30) Ã— 0.0015 = 0.003DCUã€‚

ï¼ˆ2ï¼‰å¦‚è¶…å‡ºå®¹é‡ä¸è¶³1GBï¼ŒæŒ‰1GBè®¡ç®—;

ï¼ˆ3ï¼‰è´¦æˆ·ä½™é¢ä¸è¶³æ—¶ï¼Œå°†ä¼˜å…ˆä¿ç•™æ•°æ®ï¼Œå¹¶äº§ç”Ÿè®¡è´¹ï¼Œå¹³å°ä¸ä¼šç«‹å³æ¸…ç†æ‚¨çš„æ•°æ®ã€‚å¦‚è´¦å·æ¬ è´¹è¶…10DCUï¼Œå¹³å°å°†ä¿ç•™æ¸…ç†æ•°æ®çš„æƒåŠ›ï¼ˆè€ƒè™‘åˆ°æ•°æ®çš„é‡è¦æ€§ï¼Œä¼šè°¨æ…è€ƒè™‘æ¸…ç†ç”¨æˆ·æ•°æ®ï¼‰ã€‚å¦‚å› å¹³å°æœªåŠæ—¶æ¸…ç†æ•°æ®å¯¼è‡´æŒç»­æ‰£è´¹ï¼Œè¶…å‡º10DCUçš„æ¬ é¢å¹³å°å°†ä¸ºæ‚¨ä½¿ç”¨æ‰©å±•åŒ…è¡¥æ¬ é¢ã€‚

ä¸¾ä¾‹ï¼šè´¦æˆ·æ¬ è´¹5DCUï¼Œå°†ç”±ç”¨æˆ·è‡ªè¡Œæ‰¿æ‹…5DCUæ¬ é¢ï¼›æ­¤æ—¶å¹³å°ä»æŒç»­æ‰£è´¹ï¼Œè‡´æ¬ è´¹è¾¾20DCUï¼Œæ­¤æ—¶ç”¨æˆ·å¯è”ç³»å®¢æœè¡¥10DCUä»£é‡‘åˆ¸ã€‚



## ç»“è½¬
å¥—é¤æœ‰æ•ˆæœŸä¸º30å¤©ï¼ŒæœŸé—´æœªæ¶ˆè€—çš„ç®—åŠ›å°†ä¸”ä»…å°†ç»“è½¬30å¤©ï¼Œç»“è½¬åçš„ç®—åŠ›å¤„äºæœªæ¿€æ´»çŠ¶æ€ã€‚åœ¨ç»“è½¬å‘¨æœŸå†…å†æ¬¡è®¢é˜…ï¼Œè¿™éƒ¨åˆ†ç®—åŠ›å°†è¢«æ¿€æ´»ï¼Œä½†æ— æ³•å†æ¬¡ç»“è½¬ï¼›è‹¥æ— å†æ¬¡è®¢é˜…ï¼Œè¿™éƒ¨åˆ†ç®—åŠ›å°†æ— æ³•ç»§ç»­ä½¿ç”¨ã€‚

ä¸¾ä¾‹ï¼š
å°æ˜åœ¨4æœˆ1æ—¥è®¢é˜…äº†ä¸€ä¸ªæœˆå°é²œç‰ˆå¥—é¤ï¼Œåœ¨4æœˆ30æ—¥å‰©ä½™10DCUç®—åŠ›æœªä½¿ç”¨ï¼Œ é‚£ä¹ˆåœ¨5æœˆ1æ—¥è´¦å·å†…ä»ä¼šç•™æœ‰10DCUç®—åŠ›ï¼Œä½†è¯¥éƒ¨åˆ†ç®—åŠ›å°šå¤„äºæœªæ¿€æ´»çŠ¶æ€ã€‚å°æ˜åœ¨5æœˆ15æ—¥å†æ¬¡è®¢é˜…äº†ä¸€ä¸ªæœˆåˆçº§ç‰ˆå¥—é¤ï¼Œæ­¤æ—¶10DCUç®—åŠ›æ¿€æ´»ï¼Œè´¦æˆ·å†…åˆè®¡æœ‰66.6DCUç®—åŠ›ã€‚å‡è®¾å°æ˜åœ¨6æœˆ13æ—¥å‰æ²¡æœ‰æ¶ˆè€—ä»»ä½•ç®—åŠ›ï¼Œé‚£ä¹ˆåœ¨6æœˆ14æ—¥ï¼Œ10DCUè¿‡æœŸï¼Œå…¶ç®—åŠ›ä½™é¢å°†ä¸º56.6DCUï¼Œä¸”å¤„äºæœªæ¿€æ´»çŠ¶æ€ã€‚

## å‡çº§ä¸ç»­è´¹
è®¢é˜…æ›´é«˜æƒç›Šçš„å¥—é¤æ—¶ï¼Œæ”¯ä»˜æˆåŠŸåå‡çº§å°†ç«‹å³ç”Ÿæ•ˆï¼Œæœ‰æ•ˆæœŸä¸º30å¤©ã€‚åŸå¥—é¤ç®—åŠ›çš„æœ‰æ•ˆæœŸåŒæ­¥åˆ·æ–°ï¼Œå°†åœ¨30å¤©åè¿›å…¥ç»“è½¬å‘¨æœŸã€‚

å¦‚æœè®¢é˜…æ›´ä½æƒç›Šçš„å¥—é¤ï¼Œæˆ–ç»­è´¹ç›¸åŒæƒç›Šçš„å¥—é¤ï¼Œæ–°è®¢é˜…ä¼šä»å½“å‰å‘¨æœŸç»“æŸåå¼€å§‹ç”Ÿæ•ˆã€‚åœ¨å½“å‰å‘¨æœŸå†…æ— æ³•ä½¿ç”¨ä¸‹ä¸ªå‘¨æœŸçš„ç®—åŠ›ã€‚

## æ€»ç»“
ç®—åŠ›æ‰£å‡é¡ºåºä¸ºï¼šç»“è½¬ç®—åŠ›>æ‰©å±•åŒ…>ï¼ˆä½çº§ï¼‰å¥—é¤å†…ç®—åŠ›>ï¼ˆé«˜çº§ï¼‰å¥—é¤ç®—åŠ›ã€‚

[^å®é™…è¿è¡Œ]:åªåœ¨å ç”¨GPUæ—¶è®¡è´¹ï¼Œå…¶ä»–æ—¶é—´åˆ™ä¸è®¡è´¹ï¼Œå¦‚æ–‡ä»¶ä¸Šä¼ ä¸ä¸‹è½½ã€ç¯å¢ƒé…ç½®ç­‰ã€‚
